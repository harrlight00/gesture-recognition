{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openCV-python in c:\\users\\harrl\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (4.0.0.21)\n",
      "Requirement already satisfied: numpy>=1.14.5 in c:\\users\\harrl\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from openCV-python) (1.16.2)\n",
      "Requirement already satisfied: imutils in c:\\users\\harrl\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (0.5.2)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install openCV-python\n",
    "!{sys.executable} -m pip install imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def current_milli_time():\n",
    "    t = time.time()\n",
    "    ms = t * 1000\n",
    "    rms = round(ms)\n",
    "    ims = int(rms)\n",
    "    return ims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "backSub = cv2.createBackgroundSubtractorMOG2()\n",
    "    \n",
    "#Add various templates to arrays\n",
    "templates=[] #Templates for static gestures (left and right hand)\n",
    "templates.append(cv2.imread(\"Templates/peace_template_R.jpg\", -1))\n",
    "templates.append(cv2.imread(\"Templates/peace_template_L.jpg\", -1))\n",
    "templates.append(cv2.imread(\"Templates/hand_template_R.jpg\", -1))\n",
    "templates.append(cv2.imread(\"Templates/hand_template_L.jpg\", -1))\n",
    "gesture_templates=[] #Templates for finger wave (various angles)\n",
    "gesture_templates.append(cv2.imread(\"Templates/g1.jpg\", -1))\n",
    "gesture_templates.append(cv2.imread(\"Templates/g2.jpg\", -1))\n",
    "gesture_templates.append(cv2.imread(\"Templates/g3.jpg\", -1))\n",
    "gesture_templates.append(cv2.imread(\"Templates/g4.jpg\", -1))\n",
    "\n",
    "#Process each template to return a white/black threshold map to identify hand shape\n",
    "for i in range(len(templates)):\n",
    "    template = templates[i]\n",
    "    template = cv2.cvtColor(template, cv2.COLOR_BGR2GRAY)\n",
    "    template = cv2.GaussianBlur(template,(5,5),0)\n",
    "    ret,template = cv2.threshold(template,200,255,cv2.THRESH_BINARY_INV)\n",
    "    templates[i]=template\n",
    "for i in range(len(gesture_templates)):\n",
    "    template = gesture_templates[i]\n",
    "    template = cv2.cvtColor(template, cv2.COLOR_BGR2GRAY)\n",
    "    template = cv2.GaussianBlur(template,(5,5),0)\n",
    "    ret,template = cv2.threshold(template,200,255,cv2.THRESH_BINARY_INV)\n",
    "    gesture_templates[i]=template\n",
    "\n",
    "# read first frame\n",
    "ret, prev_frame = cap.read()\n",
    "\n",
    "last_track = current_milli_time()\n",
    "track = []\n",
    "\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    frame_copy = frame.copy()\n",
    "\n",
    "    # Our operations on the frame come here\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    gauss = cv2.GaussianBlur(gray,(5,5),0)\n",
    "    ret,thresh2 = cv2.threshold(gauss,150,255,cv2.THRESH_BINARY_INV)\n",
    "    \n",
    "    #Detect motion\n",
    "    fgMask = backSub.apply(frame)\n",
    "    motion = False\n",
    "    for i in range(len(gesture_templates)):   #Check for each angle of hand shape\n",
    "        template = gesture_templates[i]\n",
    "        w, h = template.shape[::-1]\n",
    "        tm = cv2.matchTemplate(fgMask, template, cv2.TM_CCOEFF_NORMED)   #Template matching\n",
    "        min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(tm)\n",
    "        top_left = max_loc\n",
    "        bottom_right = (top_left[0] + w, top_left[1] + h)\n",
    "        if(max_val > 0.65):\n",
    "            motion = True  #Used to avoid static template matching if motion is detected\n",
    "            cv2.rectangle(frame_copy, top_left, bottom_right, (0,0,255), 2)  #Recognize finger shape and track\n",
    "            t = current_milli_time()\n",
    "            if (t - last_track > 200):\n",
    "                last_track = current_milli_time()\n",
    "                if (len(track) < 5):\n",
    "                    track = track + [(current_milli_time(), max_loc[1])]\n",
    "                elif (len(track) == 5):\n",
    "                    track = track[1:] + [(current_milli_time(), max_loc[1])]\n",
    "            break\n",
    "    \n",
    "    if (len(track) == 5and current_milli_time() - last_track < 3000 and track[-1][0] - track[0][0] > 1500 and abs(track[-1][1] - track[0][1]) > 40):\n",
    "        cv2.putText(frame_copy, \"Waving Finger\", (10, 20), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255))\n",
    "    \n",
    "    #If no motion, detect static templates\n",
    "    if (not motion):\n",
    "        for i in range(len(templates)):\n",
    "            template = templates[i]\n",
    "            w, h = template.shape[::-1]\n",
    "            tm = cv2.matchTemplate(thresh2, template, cv2.TM_CCOEFF_NORMED)   #Template matching\n",
    "            min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(tm)\n",
    "            top_left = max_loc\n",
    "            bottom_right = (top_left[0] + w, top_left[1] + h)\n",
    "            if(max_val>0.68 and i<=1):     #Test for peace sign match\n",
    "                cv2.rectangle(frame_copy, top_left, bottom_right, (0,255,0), 2)\n",
    "                cv2.putText(frame_copy, \"Peace Sign\", (10, 20), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0))\n",
    "                break\n",
    "            elif(max_val>0.68 and i>=2):   #Test for open hand match\n",
    "                cv2.rectangle(frame_copy, top_left, bottom_right, (255,0,0), 2)\n",
    "                cv2.putText(frame_copy, \"Hand\", (10, 20), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,0,0))\n",
    "                break\n",
    "\n",
    "    # Display the resulting frame\n",
    "    #cv2.imshow('Mask', fgMask)\n",
    "    cv2.imshow('Temp', templates[1])\n",
    "    cv2.imshow('Thresh', thresh2)\n",
    "    cv2.imshow('Output', frame_copy)\n",
    "    prev_frame=frame\n",
    "\n",
    "    #Exit capture\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
